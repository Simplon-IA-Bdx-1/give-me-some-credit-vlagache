{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GiveMeCredit Kaggle Submission\n",
    "\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Chargement du Dataset Full Give Me Credit - Kaggle*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T09:45:34.832273Z",
     "start_time": "2019-11-10T09:45:30.354054Z"
    }
   },
   "outputs": [],
   "source": [
    "from bigml.api import BigML\n",
    "from pandas import read_csv\n",
    "from ipynb.fs.defs.fonctions import features\n",
    "\n",
    "df = read_csv('https://oml-data.s3.amazonaws.com/kaggle-give-me-credit-train.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On stocke le train full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'df' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "%store df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Connexion BigML*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T09:45:34.843142Z",
     "start_time": "2019-11-10T09:45:34.837875Z"
    }
   },
   "outputs": [],
   "source": [
    "api = BigML(project=\"project/5d94a3525a213962e20002f5\") # AUTH dans docker/auth.env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Modifications du dataset Trainfull*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T09:45:38.785314Z",
     "start_time": "2019-11-10T09:45:34.845911Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load & Modifications OK\n"
     ]
    }
   ],
   "source": [
    "df = features(df)\n",
    "df.to_csv('files_csv/origin_dataset_modif.csv')\n",
    "print(\"Load & Modifications OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### *Création sur BIGML source -> dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T09:45:58.564175Z",
     "start_time": "2019-11-10T09:45:38.789576Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You don't have enough credits available: [{'credit_size': 18025114, 'credit_type': 300}]\n",
      "You'll need to buy some more credits to perform the chosen action\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-07 10:31:27,292: You don't have enough credits available: [{'credit_size': 18025114, 'credit_type': 300}]\n",
      "You'll need to buy some more credits to perform the chosen action\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The resource couldn't be created: {'code': 402, 'status': {'code': -1101, 'extra': [{'credit_size': 18025114, 'credit_type': 300}], 'message': \"You don't have enough credits available\"}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-07 10:31:27,293: The resource couldn't be created: {'code': 402, 'status': {'code': -1101, 'extra': [{'credit_size': 18025114, 'credit_type': 300}], 'message': \"You don't have enough credits available\"}}\n"
     ]
    }
   ],
   "source": [
    "# Creation d'une source\n",
    "source = api.create_source('files_csv/origin_dataset_modif.csv')\n",
    "api.ok(source)\n",
    "# Creation d'un dataset ( = source )\n",
    "origin_dataset = api.create_dataset(source)\n",
    "api.ok(origin_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Split du trainfull en Train/Test*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T09:45:58.584291Z",
     "start_time": "2019-11-10T09:45:58.566094Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to parse a resource string or structure.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-72c2d8271893>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m train_dataset = api.create_dataset(\n\u001b[1;32m      2\u001b[0m     origin_dataset, {\"name\": \"GiveMeCredit | TrainFull | Training\",\n\u001b[0;32m----> 3\u001b[0;31m                      \"sample_rate\": 0.8, \"seed\": \"my seed\"})\n\u001b[0m\u001b[1;32m      4\u001b[0m test_dataset = api.create_dataset(\n\u001b[1;32m      5\u001b[0m     origin_dataset, {\"name\": \"GiveMeCredit | TrainFull | Test\",\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/bigml/datasethandler.py\u001b[0m in \u001b[0;36mcreate_dataset\u001b[0;34m(self, origin_resource, args, wait_time, retries)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;31m# dataset from source\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0mresource_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_resource_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresource_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSOURCE_PATH\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0msource_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_source_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/bigml/resourcehandler.py\u001b[0m in \u001b[0;36mget_resource_type\u001b[0;34m(resource)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mresource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresource\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'resource'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Failed to parse a resource string or structure.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mresource_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource_re\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRESOURCE_RE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresource_re\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to parse a resource string or structure."
     ]
    }
   ],
   "source": [
    "train_dataset = api.create_dataset(\n",
    "    origin_dataset, {\"name\": \"GiveMeCredit | TrainFull | Training\",\n",
    "                     \"sample_rate\": 0.8, \"seed\": \"my seed\"})\n",
    "test_dataset = api.create_dataset(\n",
    "    origin_dataset, {\"name\": \"GiveMeCredit | TrainFull | Test\",\n",
    "                     \"sample_rate\": 0.8, \"seed\": \"my seed\",\n",
    "                     \"out_of_bag\": True})\n",
    "print(\"Split OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Création d'un modele ensemble sur la partie Train du dataset ( objective_field = ce qu'on cherche à prédire)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T09:45:58.589188Z",
     "start_time": "2019-11-10T09:45:30.357Z"
    }
   },
   "outputs": [],
   "source": [
    "ensemble = api.create_ensemble(train_dataset , {\"objective_field\" : \"SeriousDlqin2yrs\"})\n",
    "print(\"Création model OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Création et téléchargement de l'évaluation de notre modèle*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T09:45:58.590611Z",
     "start_time": "2019-11-10T09:45:30.359Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluation = api.create_evaluation(ensemble, test_dataset)\n",
    "api.export(evaluation, filename=\"EvaluationModel/my_evaluation_model.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Verification du modele sur les 20% du Train Full et téléchargement*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T09:45:58.592534Z",
     "start_time": "2019-11-10T09:45:30.361Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_prediction = api.create_batch_prediction(ensemble, test_dataset,{\"header\": True, \"all_fields\": True, \"probabilities\": True})\n",
    "api.ok(batch_prediction)\n",
    "api.download_batch_prediction(batch_prediction,filename='files_csv/GiveMeCredit_Review_Ensemble.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Modifications fichier test kaggle nouvelles features*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T09:47:06.214954Z",
     "start_time": "2019-11-10T09:46:57.839715Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'df_test_kaggle' (DataFrame)\n",
      "Load & Modifications OK\n"
     ]
    }
   ],
   "source": [
    "df_test_kaggle = read_csv('https://oml-data.s3.amazonaws.com/kaggle-give-me-credit-test.csv', index_col=0)\n",
    "%store df_test_kaggle\n",
    "df_test_kaggle = features(df_test_kaggle)\n",
    "df_test_kaggle.to_csv('files_csv/kaggle_dataset_modif.csv')\n",
    "print(\"Load & Modifications OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Création d'une source avec le fichier modifié test kaggle*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T09:45:58.595847Z",
     "start_time": "2019-11-10T09:45:30.365Z"
    }
   },
   "outputs": [],
   "source": [
    "source_kaggle = api.create_source('files_csv/kaggle_dataset_modif.csv')\n",
    "api.ok(source_kaggle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Création d'un dataset à partir de la source*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T09:45:58.597189Z",
     "start_time": "2019-11-10T09:45:30.367Z"
    }
   },
   "outputs": [],
   "source": [
    "kaggle_dataset= api.create_dataset(source_kaggle)\n",
    "api.ok(kaggle_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Prédiction de notre modèle sur le fichier test de Kaggle et téléchargement*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T09:45:58.598271Z",
     "start_time": "2019-11-10T09:45:30.369Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_prediction_kaggle = api.create_batch_prediction(ensemble, kaggle_dataset,{\"all_fields\": True,\"probabilities\": True})\n",
    "api.ok(batch_prediction_kaggle)\n",
    "api.download_batch_prediction(batch_prediction_kaggle,filename='files_csv/GiveMeCredit_Prediction_Kaggle.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Formatage du fichier de prédiction au format attendu par Kaggle*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T09:45:58.599432Z",
     "start_time": "2019-11-10T09:45:30.371Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "\n",
    "df_final_prediction = read_csv(\"files_csv/GiveMeCredit_Prediction_Kaggle.csv\")\n",
    "keep_col = ['Id','1 probability']\n",
    "new_final_prediction = df_final_prediction[keep_col]\n",
    "new_final_prediction.rename(columns={'1 probability':'Probability'}, inplace=True)\n",
    "new_final_prediction.to_csv('files_csv/GiveMeCredit_Kaggle_format.csv', index=False)\n",
    "print(\"Modifications OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Envoi de nos résultats à Kaggle*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T09:45:58.600483Z",
     "start_time": "2019-11-10T09:45:30.372Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import kaggle\n",
    "# submission_file = 'files_csv/GiveMeCredit_Kaggle_format.csv'\n",
    "# kaggle.api.competition_submit(submission_file, \"BigML ensemble\", \"GiveMeSomeCredit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
