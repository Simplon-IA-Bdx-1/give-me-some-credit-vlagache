{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Création d'un model xgboost + Envoi Kaggle*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T08:26:57.973820Z",
     "start_time": "2019-11-16T08:26:57.949813Z"
    }
   },
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from numpy import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Import Train full*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T08:26:59.283717Z",
     "start_time": "2019-11-16T08:26:57.978170Z"
    }
   },
   "outputs": [],
   "source": [
    "train_full = read_csv('files_csv/origin_dataset_modif.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *SEED*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T08:26:59.302770Z",
     "start_time": "2019-11-16T08:26:59.288782Z"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Auc en fonction de split différents ( pour avoir le meilleur split )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T08:26:59.320870Z",
     "start_time": "2019-11-16T08:26:59.305365Z"
    }
   },
   "outputs": [],
   "source": [
    "# from xgboost import XGBClassifier\n",
    "# from sklearn import metrics\n",
    "\n",
    "# def split_auc(n):\n",
    "    \n",
    "#     SEED = 42\n",
    "#     random.seed(SEED)\n",
    "    \n",
    "#     VAL_SIZE = n\n",
    "#     target_column = 'SeriousDlqin2yrs'\n",
    "#     train, val = train_test_split(train_full, test_size=VAL_SIZE)\n",
    "    \n",
    "#     path_train = f\"test_split/train_sk_{1-n}.csv\"\n",
    "#     path_val = f\"test_split/val_sk_{n}.csv\"\n",
    "\n",
    "#     train.to_csv(path_train)\n",
    "#     val.to_csv(path_val)\n",
    "    \n",
    "#     # Load prepared dataset \n",
    "    \n",
    "#     train_prepared = read_csv(path_train, index_col=0)\n",
    "#     val_prepared = read_csv(path_val, index_col=0)\n",
    "    \n",
    "#     # On separe Output des autres valeurs dans le train\n",
    "#     X_train = train_prepared.drop(target_column, axis=1).values\n",
    "#     y_train = train_prepared[target_column].values\n",
    "    \n",
    "#     # On separe Output des autres valeurs dans le val\n",
    "#     X_val = val_prepared.drop(target_column, axis=1).values\n",
    "#     y_val = val_prepared[target_column].values\n",
    "    \n",
    "#     # on entraine un modele\n",
    "#     model = XGBClassifier()\n",
    "#     model.fit(X_train, y_train)\n",
    " \n",
    "#     # Verification \n",
    "#     y_val_proba = model.predict_proba(X_val)\n",
    "#     y_val_proba = y_val_proba[:,1] # 1 Proba \n",
    "#     # AUC \n",
    "#     auc = metrics.roc_auc_score(y_val, y_val_proba)\n",
    "#     return auc\n",
    "\n",
    "# i = 0.1\n",
    "# best_auc = 0\n",
    "# best_split_val = 0\n",
    "# while i <= 0.9:\n",
    "#     print(f\" Pour train = {1-i} et val =  {i} , auc = {split_auc(i)}\")\n",
    "#     if split_auc(i) > best_auc:\n",
    "#         best_auc = split_auc(i)\n",
    "#         best_split_val = i\n",
    "#     i += 0.1\n",
    "    \n",
    "    \n",
    "    \n",
    "# print(f\"{best_split_val} : {best_auc}\")\n",
    "    \n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Split train full*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T08:27:03.659301Z",
     "start_time": "2019-11-16T08:26:59.325377Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train full shape: (150000, 18)\n",
      "Train shape: (105000, 18)\n",
      "Val shape: (45000, 18)\n"
     ]
    }
   ],
   "source": [
    "VAL_SIZE = 0.3 # Best auc with val_Size = 0.3\n",
    "train, val = train_test_split(train_full, test_size=VAL_SIZE)\n",
    "\n",
    "print(\"Train full shape: \" + str(train_full.shape))\n",
    "print(\"Train shape: \" + str(train.shape))\n",
    "print(\"Val shape: \" + str(val.shape))\n",
    "\n",
    "train.to_csv(\"files_csv/train_sk.csv\")\n",
    "val.to_csv(\"files_csv/val_sk.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Load prepared dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T08:27:04.601508Z",
     "start_time": "2019-11-16T08:27:03.664007Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'train_prepared' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "train_prepared = read_csv('files_csv/train_sk.csv', index_col=0)\n",
    "%store train_prepared\n",
    "val_prepared = read_csv('files_csv/val_sk.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T11:31:37.206472Z",
     "start_time": "2019-11-06T11:31:37.203853Z"
    }
   },
   "source": [
    "#### *y_train = Seriousdlsin2yrs*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T08:27:04.618368Z",
     "start_time": "2019-11-16T08:27:04.607398Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "target_column = 'SeriousDlqin2yrs'\n",
    "y_train = train_prepared[target_column].values\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T11:32:19.092310Z",
     "start_time": "2019-11-06T11:32:19.089985Z"
    }
   },
   "source": [
    "#### Tout le train sans la colonne output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T08:27:04.672234Z",
     "start_time": "2019-11-16T08:27:04.622132Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[1.86299478e-01, 5.50000000e+01, 0.00000000e+00, ...,\n",
      "        2.19745064e+03, 0.00000000e+00, 5.00000000e+00],\n",
      "       [7.60345836e-01, 5.50000000e+01, 1.00000000e+00, ...,\n",
      "        8.40214984e+03, 1.00000000e+00, 9.00000000e+00],\n",
      "       [1.01499674e-01, 3.90000000e+01, 0.00000000e+00, ...,\n",
      "        6.38117503e+03, 0.00000000e+00, 4.00000000e+00],\n",
      "       ...,\n",
      "       [6.87882910e-02, 4.90000000e+01, 0.00000000e+00, ...,\n",
      "        9.14673332e+02, 0.00000000e+00, 6.00000000e+00],\n",
      "       [2.19630062e-01, 3.60000000e+01, 0.00000000e+00, ...,\n",
      "        1.46202532e+03, 0.00000000e+00, 2.00000000e+00],\n",
      "       [2.08050838e-01, 6.20000000e+01, 1.00000000e+00, ...,\n",
      "        8.94810519e+03, 2.00000000e+00, 4.00000000e+00]])\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "X_train = train_prepared.drop(target_column, axis=1).values\n",
    "pprint(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T12:45:14.792140Z",
     "start_time": "2019-11-06T12:45:14.789191Z"
    }
   },
   "source": [
    "#### *Pareil pour le val_set*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T08:27:04.689221Z",
     "start_time": "2019-11-16T08:27:04.678904Z"
    }
   },
   "outputs": [],
   "source": [
    "X_val = val_prepared.drop(target_column, axis=1).values\n",
    "y_val = val_prepared[target_column].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T12:47:17.364182Z",
     "start_time": "2019-11-06T12:47:17.361762Z"
    }
   },
   "source": [
    "### *Prepared train set*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T08:27:13.437100Z",
     "start_time": "2019-11-16T08:27:04.692616Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'model' (XGBClassifier)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "%store model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Apply model to val set*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T08:27:13.564041Z",
     "start_time": "2019-11-16T08:27:13.439020Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99076664 0.00923336]\n",
      " [0.988792   0.01120799]\n",
      " [0.9894754  0.01052456]\n",
      " ...\n",
      " [0.94266886 0.05733114]\n",
      " [0.7797888  0.22021121]\n",
      " [0.8398806  0.1601194 ]]\n"
     ]
    }
   ],
   "source": [
    "y_val_proba = model.predict_proba(X_val)\n",
    "print(y_val_proba) # 1 Proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T08:27:13.583489Z",
     "start_time": "2019-11-16T08:27:13.565740Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00923336 0.01120799 0.01052456 ... 0.05733114 0.22021121 0.1601194 ]\n"
     ]
    }
   ],
   "source": [
    "y_val_proba = y_val_proba[:,1]\n",
    "print(y_val_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T08:27:13.700682Z",
     "start_time": "2019-11-16T08:27:13.589833Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8649011097304256"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.roc_auc_score(y_val, y_val_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T12:59:19.883601Z",
     "start_time": "2019-11-06T12:59:19.880803Z"
    }
   },
   "source": [
    "### *Envoi Kaggle*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Prédiction sur le fichier kaggle et mise en forme*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T08:27:14.931175Z",
     "start_time": "2019-11-16T08:27:13.702746Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "kaggle_prepared = read_csv('files_csv/kaggle_dataset_modif.csv', index_col=0)\n",
    "X_kag = kaggle_prepared.drop(target_column, axis=1).values\n",
    "y_kag = kaggle_prepared[target_column].values\n",
    "y_kag_proba =  model.predict_proba(X_kag)[:,1] # toutes les lignes colonnes 1\n",
    "\n",
    "\n",
    "Id = [i+1 for i in range(len(X_kag))]\n",
    "d = {'Id': Id, 'Probability': y_kag_proba}\n",
    "kaggle_df = pd.DataFrame(data=d)\n",
    "kaggle_df.to_csv(\"files_csv/prediction_sk.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Envoi Kaggle*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T08:27:20.365563Z",
     "start_time": "2019-11-16T08:27:14.933135Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.70M/1.70M [00:05<00:00, 315kB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Successfully submitted to Give Me Some Credit"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kaggle\n",
    "submission_file = 'files_csv/prediction_sk.csv'\n",
    "kaggle.api.competition_submit(submission_file, \"BigML ensemble\", \"GiveMeSomeCredit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
